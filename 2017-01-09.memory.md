# Why you're wasting all that memory
## A Strange Phenomena
Every developer learns early on in their career about the CPU / Memory tradeoff: for most tasks you can ease the burden on the CPU by using more memory.  However, whether you're using Javascript or Go or HackerNewsHypeLangOfTheMonth, typical architectures of today tend to remain CPU heavy while the majority of the RAM goes unused.  In fact, there's even pride in writing low-memory processes. High memory use is seen as a symptom of buggy code that contains memory leaks, instead of intentional design.  While this makes sense for frontend applications, server-side processes should try to maximize resource utilization to reduce the total number of machines needed.  This isn't a ground breaking concept, most programmers understand this but the question remains: why are very few people writing code that intentionally uses memory?

## Starting Simple
To understand where the challenges are let's start simple.  It's actually quite easy to write a processes that uses memory effectively.  It's likely you've done so already at some point in your career.  Let's use JavaScript for now because I know you love it.
#### Fetch User
```javascript
const user_cache = {}

function fetch(id) {
	let match = user_cache[id]
	if (!match) {
		match = from_db(id)
		user_cache[id] = match
	}
	return match
}

const one = fetch('user1')
const two = fetch('user1')
```
Hooray! This seems to work pretty well.  Very simply, we maintain a map in memory of `id -> user`. When a user is requested we check to see if we already have them in memory and if so we return the cached value.  Otherwise we load them from the DB and save the data to the cache before returning.  Now we only ever do a DB read when the user is first requested and from then on serve the data from memory at blazing fast high octane speeds!

There is a challenge though, we need to handle updates to the user data.  This is fairly simple in this scenario as well

#### Update User
```javascript
const user_cache = {}

function fetch(id) {
	let match = user_cache[id]
	if (!match) {
		match = from_db(id)
		user_cache[id] = match
	}
	return match
}

function update(id, data) {
	user_cache[id] = data
	write_db(id, data)
}

const one = fetch('user1')
update('user1', {
    ...one,
    name: 'New Guy'
})
const two = fetch('user1')
```
We've solved that challenge quite gracefully.  Whenever we update a user, we make sure to update the data in the cache.  This way no one is ever reading out of sync data. If you have a lot of users you will have to rotate items out of the cache with a [Cache Replacement Policy](https://en.wikipedia.org/wiki/Cache_replacement_policies#Policies) but we'll pause here for now.

## Distribution Ruins Everything
You can get pretty far scaling your single server up vertically and caching more of your data in memory, but that's boring.  Since you're building the next unicorn you will inevitably need to spin up multiple servers to handle all that traffic from hitting the front page of Product Hunt.  This is where things get interesting and most architectures give up on using in process memory.

Consider the following scenario.

1. User signs up on **server-a**.  Their data is cached in memory.
2. User comes back later and connects to **server-b** and updates their name.  This new data is cached in memory.
3. User comes back another time (yippee retention) and connects to **server-a**.  They check their profile and their name isn't updated since the initial data from signup is still cached!

This is the classic Cache Syncing problem.  When you have distributed caches you need to ensure the data updated at one cache is propagated to all other caches referencing the same data.  If this sounds hard, it gets even harder when you attempt it.  You'll be exposed to constraints like the CAP theorem and deal with challenges of server discovery, developing a communication protocol, handling node failures, etc.  At this point you may correctly conclude that it's not worth the headache of having an in process cache and opt to run more servers instead and scale up your database.

We have now found the answer to why developers aren't using memory, it's just too freaking hard! State is challenging in a distributed system so most opt to create stateless processes and let the database handle the problems that come with state.  However if we want to level up our architecture let's look at some options for building a distributed, stateful system.


## You're thinking Redis
// todo

## Elixir is the Elixir
// todo
